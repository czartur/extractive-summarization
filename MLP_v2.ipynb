{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import custom_utils\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 40668\n",
      "Test: 14525\n",
      "Valid: 17430\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>speakers</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70575</th>\n",
       "      <td>Yeah I think it should be a little distinct fr...</td>\n",
       "      <td>PM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19197</th>\n",
       "      <td>Okay , my turn .</td>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32883</th>\n",
       "      <td>but when we want a scrolling wheel w we also n...</td>\n",
       "      <td>PM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66445</th>\n",
       "      <td>Yeah .</td>\n",
       "      <td>UI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67299</th>\n",
       "      <td>and it still looks very fancy .</td>\n",
       "      <td>PM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences speakers  labels\n",
       "70575  Yeah I think it should be a little distinct fr...       PM       0\n",
       "19197                                   Okay , my turn .       ID       0\n",
       "32883  but when we want a scrolling wheel w we also n...       PM       1\n",
       "66445                                             Yeah .       UI       0\n",
       "67299                    and it still looks very fancy .       PM       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read\n",
    "sentences, speakers, labels = custom_utils.read_data(\"training\", \"training_labels.json\")\n",
    "\n",
    "# split\n",
    "df = pd.DataFrame({\"sentences\" : sentences, \"speakers\" : speakers, \"labels\" : labels})\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=69, stratify=df.labels)\n",
    "\n",
    "train, valid = train_test_split(train, test_size=0.3, random_state=69, stratify=train.labels)\n",
    "\n",
    "\n",
    "print(f\"Train: {len(train)}\\nTest: {len(test)}\\nValid: {len(valid)}\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\astus\\code\\extractive-summarization\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Batches: 100%|██████████| 1271/1271 [00:29<00:00, 42.92it/s]\n",
      "Batches: 100%|██████████| 545/545 [00:11<00:00, 49.38it/s]\n",
      "Batches: 100%|██████████| 454/454 [00:19<00:00, 22.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# hot encoder for speakers\n",
    "switcher = {\n",
    "    \"PM\" : [1,0,0,0],\n",
    "    \"ME\" : [0,1,0,0],\n",
    "    \"UI\" : [0,0,1,0],\n",
    "    \"ID\" : [0,0,0,1]\n",
    "}\n",
    "\n",
    "# embed\n",
    "bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "train_sentences = bert.encode(train['sentences'].to_numpy(), convert_to_tensor=True, show_progress_bar=True).to(device)\n",
    "train_speaker = torch.Tensor([switcher[el] for el in train['speakers']]).to(device)\n",
    "train_len = torch.Tensor([[len(sentence.split())] for sentence in train['sentences']]).to(device)\n",
    "train_X = torch.cat((train_sentences, train_speaker, train_len), dim=1)\n",
    "train_y = torch.tensor(train['labels'].to_numpy())\n",
    "\n",
    "valid_sentences = bert.encode(valid['sentences'].to_numpy(), convert_to_tensor=True, show_progress_bar=True).to(device)\n",
    "valid_speaker = torch.Tensor([switcher[el] for el in valid['speakers']]).to(device)\n",
    "valid_len = torch.Tensor([[len(sentence.split())] for sentence in valid['sentences']]).to(device)\n",
    "valid_X = torch.cat((valid_sentences, valid_speaker, valid_len), dim=1)\n",
    "valid_y = torch.tensor(valid['labels'].to_numpy())\n",
    "\n",
    "test_sentences = bert.encode(test['sentences'].to_numpy(), convert_to_tensor=True, show_progress_bar=True).to(device)\n",
    "test_speaker = torch.Tensor([switcher[el] for el in test['speakers']]).to(device)\n",
    "test_len = torch.Tensor([[len(sentence.split())] for sentence in test['sentences']]).to(device)\n",
    "test_X = torch.cat((test_sentences, test_speaker, test_len), dim=1)\n",
    "test_y = torch.tensor(test['labels'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def data_loader(batch_size):\n",
    "    # create tensor datasets\n",
    "    trainset = TensorDataset((train_X).to(device), (train_y).to(device))\n",
    "    validset = TensorDataset((valid_X).to(device), (valid_y).to(device))\n",
    "    testset = TensorDataset((test_X).to(device), (test_y).to(device))\n",
    "\n",
    "    # create dataloaders\n",
    "    train_loader = DataLoader(trainset, shuffle=True, batch_size=batch_size, generator=torch.Generator(device=device))\n",
    "    valid_loader = DataLoader(validset, shuffle=True, batch_size=batch_size, generator=torch.Generator(device=device))\n",
    "    test_loader = DataLoader(testset, shuffle=True, batch_size=batch_size, generator=torch.Generator(device=device))\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(params):\n",
    "    # Model\n",
    "    n_layers = params['n_layers']\n",
    "    layers = []\n",
    "\n",
    "    in_features = params['input_size']\n",
    "    for i in range(n_layers):\n",
    "        out_features = params[f'n_{i}_size']\n",
    "        layers.append(torch.nn.Linear(in_features, out_features))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        # suggest dropout\n",
    "        p = params['n_p']\n",
    "        layers.append(torch.nn.Dropout(p))\n",
    "\n",
    "        # updating next layer size\n",
    "        in_features = out_features\n",
    "        \n",
    "    layers.append(torch.nn.Linear(in_features, params['output_size']))\n",
    "    model = torch.nn.Sequential(*layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(train['labels'].to_numpy()), y=train['labels'].to_numpy())\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights).float()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from torchmetrics.classification import F1Score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def train_MLP(trial):\n",
    "    \n",
    "    params = {\n",
    "        \"n_layers\" : trial.suggest_int(\"n_layers\", 3, 7),\n",
    "        \"input_size\" : int(train_X.shape[1]),\n",
    "        \"output_size\" : 2,\n",
    "        \"n_p\" : trial.suggest_float(\"n_p\", 0.4, 0.8),\n",
    "        \"lr\" : trial.suggest_float(\"lr\", 1e-4, 1e-3),\n",
    "        \"weight_decay\" : trial.suggest_float(\"weight_decay\", 1e-5, 1e-4),\n",
    "        \"batch_size\" : trial.suggest_int(\"batch_size\", 400, 600)\n",
    "    }\n",
    "    for i in range(trial.params[\"n_layers\"]):\n",
    "        params[f\"n_{i}_size\"] = trial.suggest_int(f\"n_{i}_size\", 200, 800)\n",
    "\n",
    "    \n",
    "    model = MLP(params)\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train['labels'].to_numpy()), y=train['labels'].to_numpy())\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights).float()) \n",
    "    # criterion = torch.nn.CrossEntropyLoss() \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"], weight_decay=params[\"weight_decay\"])\n",
    "    f1 = F1Score(task='binary', num_classes=params['output_size']).to(device)\n",
    "\n",
    "    train_loader, valid_loader, test_loader = data_loader(params[\"batch_size\"])\n",
    "    \n",
    "    n_epochs = 20\n",
    "    it = 0\n",
    "    hst_train_loss = [] \n",
    "    hst_valid_loss = []\n",
    "    hst_f1_score = []\n",
    "\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    patience = 10\n",
    "    for epoch in range(n_epochs):\n",
    "        if patience == 0: break\n",
    "        for samples, labels in train_loader:\n",
    "            if patience == 0: break\n",
    "            it += 1\n",
    "\n",
    "            # train step\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(samples)\n",
    "            loss = criterion(out, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            if it % 100 == 0:\n",
    "                model.eval()\n",
    "\n",
    "                train_loss = loss.cpu().detach().numpy() / 1\n",
    "                valid_loss = 0\n",
    "                f1_score = 0\n",
    "                for samples, labels in valid_loader:\n",
    "                    out = model(samples)\n",
    "                    loss = criterion(out, labels)\n",
    "                    valid_loss += loss.cpu().detach().numpy() / len(valid_loader)\n",
    "                    f1_score += f1(labels, out.argmax(dim=1)).cpu().detach().numpy() / len(valid_loader)\n",
    "                \n",
    "                # early stopping\n",
    "                if valid_loss < best_valid_loss:\n",
    "                    best_valid_loss = valid_loss\n",
    "                    best_weights = model.state_dict()\n",
    "                    patience = 10\n",
    "                else:\n",
    "                    patience -= 1 \n",
    "                \n",
    "                hst_train_loss.append(train_loss)\n",
    "                hst_valid_loss.append(valid_loss)\n",
    "                hst_f1_score.append(f1_score)\n",
    "\n",
    "                print('Iter: {} | Train Loss: {} | Val Loss: {} | F1-score: {}'.format(it, train_loss, valid_loss, f1_score))\n",
    "    \n",
    "    # objective function criterion\n",
    "    combined = sorted(zip(hst_valid_loss, hst_f1_score), key=lambda x : x[0])\n",
    "    _, scores = zip(*combined)\n",
    "    qtd = 3\n",
    "    final_score = sum(scores[:qtd]) / qtd\n",
    "\n",
    "    torch.save(best_weights, f\"models/mlp_{trial.number}.pt\")\n",
    "    results = {\n",
    "        \"score\" : final_score,\n",
    "        \"params\" : params,\n",
    "        \"valid_loss\" : hst_valid_loss,\n",
    "        \"train_loss\" : hst_train_loss,\n",
    "        \"f1_score\" : hst_f1_score, \n",
    "    }\n",
    "    json.dump(results, open(f\"models/mlp_results_{trial.number}.json\", \"w\"))\n",
    "\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:20:51,893] A new study created in memory with name: no-name-ef86ba72-dd20-4c8c-9e04-48d7bed8f249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.36012235283851624 | Val Loss: 0.3319387937846937 | F1-score: 0.43481223206771036\n",
      "Iter: 200 | Train Loss: 0.3128753900527954 | Val Loss: 0.3253439374660191 | F1-score: 0.46063435940366043\n",
      "Iter: 300 | Train Loss: 0.29471731185913086 | Val Loss: 0.32281238860205597 | F1-score: 0.4495595034800079\n",
      "Iter: 400 | Train Loss: 0.28942471742630005 | Val Loss: 0.32024350291804266 | F1-score: 0.5261493419346057\n",
      "Iter: 500 | Train Loss: 0.3100268244743347 | Val Loss: 0.32028789504578237 | F1-score: 0.5242662116100913\n",
      "Iter: 600 | Train Loss: 0.3141099214553833 | Val Loss: 0.31767960833875764 | F1-score: 0.48578170804600956\n",
      "Iter: 700 | Train Loss: 0.3051414489746094 | Val Loss: 0.31737125233600005 | F1-score: 0.5308804135573537\n",
      "Iter: 800 | Train Loss: 0.3383527398109436 | Val Loss: 0.31764967818009215 | F1-score: 0.5351550751610806\n",
      "Iter: 900 | Train Loss: 0.29451027512550354 | Val Loss: 0.3179136436236532 | F1-score: 0.48060188167973583\n",
      "Iter: 1000 | Train Loss: 0.30503761768341064 | Val Loss: 0.3157676027009362 | F1-score: 0.5270729284537466\n",
      "Iter: 1100 | Train Loss: 0.3127537667751312 | Val Loss: 0.3168641360182511 | F1-score: 0.534838702333601\n",
      "Iter: 1200 | Train Loss: 0.3175903856754303 | Val Loss: 0.31586003381955 | F1-score: 0.5458029006656848\n",
      "Iter: 1300 | Train Loss: 0.3047051429748535 | Val Loss: 0.3198315916877044 | F1-score: 0.520803278214053\n",
      "Iter: 1400 | Train Loss: 0.2892114818096161 | Val Loss: 0.31643878197983694 | F1-score: 0.5053415957250094\n",
      "Iter: 1500 | Train Loss: 0.2686725854873657 | Val Loss: 0.32102821453621516 | F1-score: 0.5219392298083555\n",
      "Iter: 1600 | Train Loss: 0.2944599688053131 | Val Loss: 0.3201328319938559 | F1-score: 0.5298993493381299\n",
      "Iter: 1700 | Train Loss: 0.3158491849899292 | Val Loss: 0.3224215766316966 | F1-score: 0.5369146670165816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:21:13,925] Trial 0 finished with value: 0.526072474948147 and parameters: {'n_layers': 4, 'n_p': 0.6130724483887233, 'lr': 0.0005326806903942525, 'weight_decay': 1.9472376819179503e-05, 'batch_size': 465, 'n_0_size': 262, 'n_1_size': 476, 'n_2_size': 734, 'n_3_size': 406}. Best is trial 0 with value: 0.526072474948147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.3177231252193451 | Val Loss: 0.3285485692322254 | F1-score: 0.3658629674464464\n",
      "Iter: 200 | Train Loss: 0.3238745927810669 | Val Loss: 0.3248340729624033 | F1-score: 0.46205563098192215\n",
      "Iter: 300 | Train Loss: 0.3223522901535034 | Val Loss: 0.3208871800452471 | F1-score: 0.4348042318597436\n",
      "Iter: 400 | Train Loss: 0.29421064257621765 | Val Loss: 0.3199586998671293 | F1-score: 0.41932765301316977\n",
      "Iter: 500 | Train Loss: 0.31475672125816345 | Val Loss: 0.3177069555968046 | F1-score: 0.4992232220247388\n",
      "Iter: 600 | Train Loss: 0.34188562631607056 | Val Loss: 0.317690746858716 | F1-score: 0.5278472304344177\n",
      "Iter: 700 | Train Loss: 0.2924685776233673 | Val Loss: 0.3164311954751611 | F1-score: 0.519834122620523\n",
      "Iter: 800 | Train Loss: 0.3139229714870453 | Val Loss: 0.3164797741919756 | F1-score: 0.5457660825923085\n",
      "Iter: 900 | Train Loss: 0.33876001834869385 | Val Loss: 0.3178023360669613 | F1-score: 0.556452208198607\n",
      "Iter: 1000 | Train Loss: 0.2849796712398529 | Val Loss: 0.3191112792119384 | F1-score: 0.4998644618317485\n",
      "Iter: 1100 | Train Loss: 0.305347204208374 | Val Loss: 0.3205601144582033 | F1-score: 0.5513789979740977\n",
      "Iter: 1200 | Train Loss: 0.30962541699409485 | Val Loss: 0.3208186011761427 | F1-score: 0.525043835863471\n",
      "Iter: 1300 | Train Loss: 0.30495575070381165 | Val Loss: 0.32669395487755537 | F1-score: 0.5252869892865419\n",
      "Iter: 1400 | Train Loss: 0.2526588439941406 | Val Loss: 0.32951601315289736 | F1-score: 0.5312804384157062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:21:39,015] Trial 1 finished with value: 0.5311491452157497 and parameters: {'n_layers': 5, 'n_p': 0.47246377406868323, 'lr': 0.0004275749981812202, 'weight_decay': 6.54390352066903e-05, 'batch_size': 546, 'n_0_size': 644, 'n_1_size': 292, 'n_2_size': 770, 'n_3_size': 504, 'n_4_size': 629}. Best is trial 1 with value: 0.5311491452157497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1500 | Train Loss: 0.27124524116516113 | Val Loss: 0.32667103223502636 | F1-score: 0.5370489470660686\n",
      "Iter: 100 | Train Loss: 0.3056701421737671 | Val Loss: 0.3290070174513636 | F1-score: 0.44943404439333323\n",
      "Iter: 200 | Train Loss: 0.3406127095222473 | Val Loss: 0.3244889314110215 | F1-score: 0.4157447106129414\n",
      "Iter: 300 | Train Loss: 0.3658142685890198 | Val Loss: 0.3219162217668586 | F1-score: 0.45671174332902253\n",
      "Iter: 400 | Train Loss: 0.31700652837753296 | Val Loss: 0.32027697724265025 | F1-score: 0.5262584919865066\n",
      "Iter: 500 | Train Loss: 0.33127617835998535 | Val Loss: 0.31942362479261455 | F1-score: 0.5252802436416214\n",
      "Iter: 600 | Train Loss: 0.3290652930736542 | Val Loss: 0.3185450708543931 | F1-score: 0.5462843977116251\n",
      "Iter: 700 | Train Loss: 0.28788450360298157 | Val Loss: 0.3173508853525728 | F1-score: 0.5381506794207804\n",
      "Iter: 800 | Train Loss: 0.27533718943595886 | Val Loss: 0.31709613993361196 | F1-score: 0.5229228445001551\n",
      "Iter: 900 | Train Loss: 0.31597191095352173 | Val Loss: 0.31675879375354665 | F1-score: 0.5001847776206763\n",
      "Iter: 1000 | Train Loss: 0.3195856809616089 | Val Loss: 0.3162356252605851 | F1-score: 0.5431262609120963\n",
      "Iter: 1100 | Train Loss: 0.31539374589920044 | Val Loss: 0.3174720809266374 | F1-score: 0.5419697995121414\n",
      "Iter: 1200 | Train Loss: 0.3173162043094635 | Val Loss: 0.31743029162690445 | F1-score: 0.44041618946436284\n",
      "Iter: 1300 | Train Loss: 0.32519009709358215 | Val Loss: 0.3189404485998928 | F1-score: 0.5396203358431121\n",
      "Iter: 1400 | Train Loss: 0.2779124975204468 | Val Loss: 0.3195933337147171 | F1-score: 0.536995110479561\n",
      "Iter: 1500 | Train Loss: 0.2994536757469177 | Val Loss: 0.32271424660811554 | F1-score: 0.5401068660053046\n",
      "Iter: 1600 | Train Loss: 0.3055359125137329 | Val Loss: 0.3201675849991876 | F1-score: 0.5613813070026604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:22:07,345] Trial 2 finished with value: 0.5220779610109759 and parameters: {'n_layers': 4, 'n_p': 0.5639652928042218, 'lr': 0.0004571559304121832, 'weight_decay': 9.835686880557039e-05, 'batch_size': 476, 'n_0_size': 564, 'n_1_size': 344, 'n_2_size': 702, 'n_3_size': 234}. Best is trial 1 with value: 0.5311491452157497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1700 | Train Loss: 0.2792925238609314 | Val Loss: 0.3259388506412507 | F1-score: 0.4254783230858882\n",
      "Iter: 100 | Train Loss: 0.38197845220565796 | Val Loss: 0.33137338490862583 | F1-score: 0.31765683073746537\n",
      "Iter: 200 | Train Loss: 0.3190828561782837 | Val Loss: 0.32542076079468985 | F1-score: 0.4398550171601146\n",
      "Iter: 300 | Train Loss: 0.3536498546600342 | Val Loss: 0.3240880087802286 | F1-score: 0.4681240822139539\n",
      "Iter: 400 | Train Loss: 0.2960451543331146 | Val Loss: 0.32018251089673294 | F1-score: 0.5250719848432039\n",
      "Iter: 500 | Train Loss: 0.3480081260204315 | Val Loss: 0.3191748975138915 | F1-score: 0.46058803796768183\n",
      "Iter: 600 | Train Loss: 0.32987678050994873 | Val Loss: 0.3242669082001636 | F1-score: 0.3529970571398734\n",
      "Iter: 700 | Train Loss: 0.32844996452331543 | Val Loss: 0.31863063103274303 | F1-score: 0.46874354858147466\n",
      "Iter: 800 | Train Loss: 0.2845161259174347 | Val Loss: 0.3174322059279994 | F1-score: 0.4686481560531414\n",
      "Iter: 900 | Train Loss: 0.30749571323394775 | Val Loss: 0.32019180137860154 | F1-score: 0.44880151983938715\n",
      "Iter: 1000 | Train Loss: 0.28733518719673157 | Val Loss: 0.317585760041287 | F1-score: 0.46685973358781707\n",
      "Iter: 1100 | Train Loss: 0.3142561614513397 | Val Loss: 0.31735261255189 | F1-score: 0.5471667200326921\n",
      "Iter: 1200 | Train Loss: 0.31397122144699097 | Val Loss: 0.3172345412404914 | F1-score: 0.5039110873874866\n",
      "Iter: 1300 | Train Loss: 0.284579873085022 | Val Loss: 0.3187077970881211 | F1-score: 0.4760765182344537\n",
      "Iter: 1400 | Train Loss: 0.3021530508995056 | Val Loss: 0.3200203666561528 | F1-score: 0.5077928485054719\n",
      "Iter: 1500 | Train Loss: 0.3039960265159607 | Val Loss: 0.3204674148245861 | F1-score: 0.5530931533951507\n",
      "Iter: 1600 | Train Loss: 0.2790551483631134 | Val Loss: 0.325533503764554 | F1-score: 0.5439119142921349\n",
      "Iter: 1700 | Train Loss: 0.3138209581375122 | Val Loss: 0.3193001605962452 | F1-score: 0.49921379434435004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:22:32,576] Trial 3 finished with value: 0.5065753211577734 and parameters: {'n_layers': 6, 'n_p': 0.5170328312049456, 'lr': 0.0005525788700125892, 'weight_decay': 3.8381533529929835e-05, 'batch_size': 459, 'n_0_size': 200, 'n_1_size': 518, 'n_2_size': 305, 'n_3_size': 362, 'n_4_size': 492, 'n_5_size': 738}. Best is trial 1 with value: 0.5311491452157497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.313728392124176 | Val Loss: 0.32763051535144 | F1-score: 0.42209292541850696\n",
      "Iter: 200 | Train Loss: 0.32531455159187317 | Val Loss: 0.3272092784896042 | F1-score: 0.3232720458146297\n",
      "Iter: 300 | Train Loss: 0.3225151300430298 | Val Loss: 0.3269605817216815 | F1-score: 0.3116848152695279\n",
      "Iter: 400 | Train Loss: 0.27113303542137146 | Val Loss: 0.3304395865310323 | F1-score: 0.35516858281511243\n",
      "Iter: 500 | Train Loss: 0.32022762298583984 | Val Loss: 0.3207049776207316 | F1-score: 0.4518768751260006\n",
      "Iter: 600 | Train Loss: 0.31971603631973267 | Val Loss: 0.3174919061588519 | F1-score: 0.5477107176274966\n",
      "Iter: 700 | Train Loss: 0.2989861071109772 | Val Loss: 0.3185915513472123 | F1-score: 0.49918922420704004\n",
      "Iter: 800 | Train Loss: 0.33260512351989746 | Val Loss: 0.3197030921777089 | F1-score: 0.5025034519759092\n",
      "Iter: 900 | Train Loss: 0.34826067090034485 | Val Loss: 0.3150547778967655 | F1-score: 0.5572954154375829\n",
      "Iter: 1000 | Train Loss: 0.30290088057518005 | Val Loss: 0.3203662073973453 | F1-score: 0.5509283375559431\n",
      "Iter: 1100 | Train Loss: 0.29585564136505127 | Val Loss: 0.32034136941938685 | F1-score: 0.5698318707220482\n",
      "Iter: 1200 | Train Loss: 0.3275996744632721 | Val Loss: 0.3186298477830308 | F1-score: 0.5434656802451971\n",
      "Iter: 1300 | Train Loss: 0.325369268655777 | Val Loss: 0.31878728035724524 | F1-score: 0.5389278332392375\n",
      "Iter: 1400 | Train Loss: 0.2817668318748474 | Val Loss: 0.319263681769371 | F1-score: 0.509918847770402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:23:00,034] Trial 4 finished with value: 0.5347317857573731 and parameters: {'n_layers': 7, 'n_p': 0.5453180354632154, 'lr': 0.0008978117009177701, 'weight_decay': 4.65490842053666e-05, 'batch_size': 544, 'n_0_size': 246, 'n_1_size': 368, 'n_2_size': 292, 'n_3_size': 739, 'n_4_size': 481, 'n_5_size': 499, 'n_6_size': 435}. Best is trial 4 with value: 0.5347317857573731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1500 | Train Loss: 0.2752302289009094 | Val Loss: 0.31894408030943433 | F1-score: 0.5610274004213738\n",
      "Iter: 100 | Train Loss: 0.37394794821739197 | Val Loss: 0.3426791039796977 | F1-score: 0.007915139580384279\n",
      "Iter: 200 | Train Loss: 0.3251515328884125 | Val Loss: 0.33218287504636324 | F1-score: 0.4475400409637353\n",
      "Iter: 300 | Train Loss: 0.3579639792442322 | Val Loss: 0.3289546958911113 | F1-score: 0.45501208152526484\n",
      "Iter: 400 | Train Loss: 0.3528248071670532 | Val Loss: 0.3274355194507501 | F1-score: 0.46185328333805775\n",
      "Iter: 500 | Train Loss: 0.3370353579521179 | Val Loss: 0.3265674679707258 | F1-score: 0.5162761494135247\n",
      "Iter: 600 | Train Loss: 0.3509226441383362 | Val Loss: 0.3239764578831501 | F1-score: 0.5086703109435546\n",
      "Iter: 700 | Train Loss: 0.37057268619537354 | Val Loss: 0.3238557806381812 | F1-score: 0.522389680147171\n",
      "Iter: 800 | Train Loss: 0.30169278383255005 | Val Loss: 0.32242449965232467 | F1-score: 0.5089870851773483\n",
      "Iter: 900 | Train Loss: 0.3638790547847748 | Val Loss: 0.3205279723191871 | F1-score: 0.496693484294109\n",
      "Iter: 1000 | Train Loss: 0.32723021507263184 | Val Loss: 0.32027417803422 | F1-score: 0.5238732252365502\n",
      "Iter: 1100 | Train Loss: 0.31883686780929565 | Val Loss: 0.3216313826732146 | F1-score: 0.5299534530211718\n",
      "Iter: 1200 | Train Loss: 0.31288161873817444 | Val Loss: 0.31921448615881115 | F1-score: 0.5358951152899326\n",
      "Iter: 1300 | Train Loss: 0.3158324360847473 | Val Loss: 0.31943730131173753 | F1-score: 0.5285892845728459\n",
      "Iter: 1400 | Train Loss: 0.32432830333709717 | Val Loss: 0.31783693493940895 | F1-score: 0.4883567866606591\n",
      "Iter: 1500 | Train Loss: 0.3276132345199585 | Val Loss: 0.31767817796804976 | F1-score: 0.5159041048624576\n",
      "Iter: 1600 | Train Loss: 0.3164799213409424 | Val Loss: 0.31765399911464787 | F1-score: 0.5134701163340837\n",
      "Iter: 1700 | Train Loss: 0.32618460059165955 | Val Loss: 0.31630422136722475 | F1-score: 0.4902393474028661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:23:28,088] Trial 5 finished with value: 0.5065378561998025 and parameters: {'n_layers': 5, 'n_p': 0.6025620934064149, 'lr': 0.00013837783407924937, 'weight_decay': 4.5684200423156565e-05, 'batch_size': 452, 'n_0_size': 792, 'n_1_size': 589, 'n_2_size': 206, 'n_3_size': 652, 'n_4_size': 209}. Best is trial 4 with value: 0.5347317857573731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1800 | Train Loss: 0.2944789528846741 | Val Loss: 0.31794334680606157 | F1-score: 0.5459363934321283\n",
      "Iter: 100 | Train Loss: 0.3511278033256531 | Val Loss: 0.3288526296615601 | F1-score: 0.3731308003266653\n",
      "Iter: 200 | Train Loss: 0.3265257179737091 | Val Loss: 0.3219054788351059 | F1-score: 0.4978406806786856\n",
      "Iter: 300 | Train Loss: 0.3259563744068146 | Val Loss: 0.32375970979531604 | F1-score: 0.42099516689777383\n",
      "Iter: 400 | Train Loss: 0.3151002526283264 | Val Loss: 0.32037148674329124 | F1-score: 0.511775878071785\n",
      "Iter: 500 | Train Loss: 0.2977781295776367 | Val Loss: 0.32023540039857235 | F1-score: 0.5508445660273233\n",
      "Iter: 600 | Train Loss: 0.31873321533203125 | Val Loss: 0.31684859196345005 | F1-score: 0.5232881118853887\n",
      "Iter: 700 | Train Loss: 0.3402663767337799 | Val Loss: 0.3160031865040462 | F1-score: 0.5193877458572388\n",
      "Iter: 800 | Train Loss: 0.3312075734138489 | Val Loss: 0.3177418172359466 | F1-score: 0.5561690221230188\n",
      "Iter: 900 | Train Loss: 0.29906758666038513 | Val Loss: 0.3175824950138728 | F1-score: 0.4257407973210018\n",
      "Iter: 1000 | Train Loss: 0.3315140902996063 | Val Loss: 0.3169912457466125 | F1-score: 0.5417224178711573\n",
      "Iter: 1100 | Train Loss: 0.3123566806316376 | Val Loss: 0.3195578247308731 | F1-score: 0.5184929599364598\n",
      "Iter: 1200 | Train Loss: 0.3006865978240967 | Val Loss: 0.31708687494198484 | F1-score: 0.5310081928968429\n",
      "Iter: 1300 | Train Loss: 0.27805450558662415 | Val Loss: 0.32171745300292975 | F1-score: 0.46475982069969174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:23:56,496] Trial 6 finished with value: 0.5281327585379283 and parameters: {'n_layers': 4, 'n_p': 0.6584242644117335, 'lr': 0.0007901233341788291, 'weight_decay': 5.1638869876167445e-05, 'batch_size': 593, 'n_0_size': 533, 'n_1_size': 486, 'n_2_size': 699, 'n_3_size': 684}. Best is trial 4 with value: 0.5347317857573731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.3505965769290924 | Val Loss: 0.32809797269957414 | F1-score: 0.23491416743823465\n",
      "Iter: 200 | Train Loss: 0.3724530041217804 | Val Loss: 0.3238323560782842 | F1-score: 0.44709636058126173\n",
      "Iter: 300 | Train Loss: 0.3227882981300354 | Val Loss: 0.3215429987226214 | F1-score: 0.5213304604802812\n",
      "Iter: 400 | Train Loss: 0.33775994181632996 | Val Loss: 0.31920358708926616 | F1-score: 0.5231357157230377\n",
      "Iter: 500 | Train Loss: 0.3222169280052185 | Val Loss: 0.31975000585828506 | F1-score: 0.5382101391042982\n",
      "Iter: 600 | Train Loss: 0.2843838632106781 | Val Loss: 0.3182240699018752 | F1-score: 0.5197438197476524\n",
      "Iter: 700 | Train Loss: 0.33718064427375793 | Val Loss: 0.3175196383680616 | F1-score: 0.4911918171814511\n",
      "Iter: 800 | Train Loss: 0.3161628544330597 | Val Loss: 0.319003176689148 | F1-score: 0.5273530857903617\n",
      "Iter: 900 | Train Loss: 0.32652604579925537 | Val Loss: 0.3178353582109724 | F1-score: 0.5404601582459041\n",
      "Iter: 1000 | Train Loss: 0.2999943792819977 | Val Loss: 0.318047377041408 | F1-score: 0.530641543865204\n",
      "Iter: 1100 | Train Loss: 0.3018573820590973 | Val Loss: 0.3184559081281934 | F1-score: 0.48274251648357935\n",
      "Iter: 1200 | Train Loss: 0.33125823736190796 | Val Loss: 0.316613907473428 | F1-score: 0.5378062060901098\n",
      "Iter: 1300 | Train Loss: 0.28451308608055115 | Val Loss: 0.31804139188357766 | F1-score: 0.5489877939224244\n",
      "Iter: 1400 | Train Loss: 0.3007066249847412 | Val Loss: 0.31885233521461487 | F1-score: 0.5268425038882665\n",
      "Iter: 1500 | Train Loss: 0.3085203468799591 | Val Loss: 0.3247917839459011 | F1-score: 0.5686480590275355\n",
      "Iter: 1600 | Train Loss: 0.26451659202575684 | Val Loss: 0.32219869664737155 | F1-score: 0.4495099084717888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:24:25,106] Trial 7 finished with value: 0.5231527271724883 and parameters: {'n_layers': 5, 'n_p': 0.624336368246498, 'lr': 0.0007808208607142803, 'weight_decay': 4.179932673722938e-05, 'batch_size': 505, 'n_0_size': 491, 'n_1_size': 326, 'n_2_size': 446, 'n_3_size': 277, 'n_4_size': 710}. Best is trial 4 with value: 0.5347317857573731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.34748050570487976 | Val Loss: 0.32665016551812487 | F1-score: 0.45576997399330144\n",
      "Iter: 200 | Train Loss: 0.31743553280830383 | Val Loss: 0.32351248264312743 | F1-score: 0.4789157330989837\n",
      "Iter: 300 | Train Loss: 0.3316381871700287 | Val Loss: 0.32144168814023333 | F1-score: 0.48898784617582963\n",
      "Iter: 400 | Train Loss: 0.33803310990333557 | Val Loss: 0.31936063269774123 | F1-score: 0.4566892474889756\n",
      "Iter: 500 | Train Loss: 0.29527679085731506 | Val Loss: 0.32111096978187564 | F1-score: 0.4562829256057739\n",
      "Iter: 600 | Train Loss: 0.3017221987247467 | Val Loss: 0.31841055949529007 | F1-score: 0.4367248664299648\n",
      "Iter: 700 | Train Loss: 0.32889190316200256 | Val Loss: 0.32041359345118203 | F1-score: 0.43827892045180017\n",
      "Iter: 800 | Train Loss: 0.31712424755096436 | Val Loss: 0.3179402858018874 | F1-score: 0.5511074086030325\n",
      "Iter: 900 | Train Loss: 0.32799825072288513 | Val Loss: 0.31727478106816615 | F1-score: 0.5371186435222626\n",
      "Iter: 1000 | Train Loss: 0.2926348149776459 | Val Loss: 0.3177382081747055 | F1-score: 0.4912227054437002\n",
      "Iter: 1100 | Train Loss: 0.29769229888916016 | Val Loss: 0.3162562847137451 | F1-score: 0.5300061265627541\n",
      "Iter: 1200 | Train Loss: 0.29208511114120483 | Val Loss: 0.3208346327145894 | F1-score: 0.5728216856718064\n",
      "Iter: 1300 | Train Loss: 0.31932610273361206 | Val Loss: 0.3189019272724788 | F1-score: 0.5568628897269566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:24:45,225] Trial 8 finished with value: 0.529269567463133 and parameters: {'n_layers': 3, 'n_p': 0.646332752242356, 'lr': 0.0007919213513706081, 'weight_decay': 9.896085629494261e-05, 'batch_size': 589, 'n_0_size': 364, 'n_1_size': 642, 'n_2_size': 298}. Best is trial 4 with value: 0.5347317857573731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1400 | Train Loss: 0.40938758850097656 | Val Loss: 0.3158190160989761 | F1-score: 0.5206839323043825\n",
      "Iter: 100 | Train Loss: 0.35067248344421387 | Val Loss: 0.33345776895682017 | F1-score: 0.4666208346684774\n",
      "Iter: 200 | Train Loss: 0.32906556129455566 | Val Loss: 0.32567177414894105 | F1-score: 0.5103862226009369\n",
      "Iter: 300 | Train Loss: 0.3258075714111328 | Val Loss: 0.3225881397724151 | F1-score: 0.40417966941992445\n",
      "Iter: 400 | Train Loss: 0.32479214668273926 | Val Loss: 0.31967292726039886 | F1-score: 0.49074116547902424\n",
      "Iter: 500 | Train Loss: 0.30603352189064026 | Val Loss: 0.3220033099253972 | F1-score: 0.5634892582893372\n",
      "Iter: 600 | Train Loss: 0.3239508867263794 | Val Loss: 0.316189788778623 | F1-score: 0.5103289047876993\n",
      "Iter: 700 | Train Loss: 0.34030601382255554 | Val Loss: 0.3155164976914724 | F1-score: 0.5069824963808061\n",
      "Iter: 800 | Train Loss: 0.33923104405403137 | Val Loss: 0.31686960061391195 | F1-score: 0.5527546097834904\n",
      "Iter: 900 | Train Loss: 0.29965758323669434 | Val Loss: 0.3173156092564265 | F1-score: 0.43158665597438817\n",
      "Iter: 1000 | Train Loss: 0.323047935962677 | Val Loss: 0.31880210737387343 | F1-score: 0.5657424678405125\n",
      "Iter: 1100 | Train Loss: 0.3043462336063385 | Val Loss: 0.3169512301683426 | F1-score: 0.5210403402646383\n",
      "Iter: 1200 | Train Loss: 0.2864135503768921 | Val Loss: 0.3214165906111399 | F1-score: 0.5350475986798604\n",
      "Iter: 1300 | Train Loss: 0.273960679769516 | Val Loss: 0.33556497693061826 | F1-score: 0.40001734693845115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:25:18,129] Trial 9 finished with value: 0.5233553369839986 and parameters: {'n_layers': 5, 'n_p': 0.4450453545316276, 'lr': 0.0003363035451889863, 'weight_decay': 8.652679875176544e-05, 'batch_size': 594, 'n_0_size': 654, 'n_1_size': 604, 'n_2_size': 454, 'n_3_size': 505, 'n_4_size': 330}. Best is trial 4 with value: 0.5347317857573731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.34425756335258484 | Val Loss: 0.34590639219139563 | F1-score: 0.0\n",
      "Iter: 200 | Train Loss: 0.3701247274875641 | Val Loss: 0.3467673234867327 | F1-score: 0.0\n",
      "Iter: 300 | Train Loss: 0.33843284845352173 | Val Loss: 0.33745975566632824 | F1-score: 0.0\n",
      "Iter: 400 | Train Loss: 0.35012558102607727 | Val Loss: 0.33107390096693334 | F1-score: 0.5037695873867382\n",
      "Iter: 500 | Train Loss: 0.2950485348701477 | Val Loss: 0.323929210503896 | F1-score: 0.5554339741215562\n",
      "Iter: 600 | Train Loss: 0.31393396854400635 | Val Loss: 0.3249242305755616 | F1-score: 0.5596899119290439\n",
      "Iter: 700 | Train Loss: 0.3512522876262665 | Val Loss: 0.34214715795083483 | F1-score: 0.557665208975474\n",
      "Iter: 800 | Train Loss: 0.30516424775123596 | Val Loss: 0.33853680888811755 | F1-score: 0.5710861231341507\n",
      "Iter: 900 | Train Loss: 0.30384665727615356 | Val Loss: 0.3257936537265777 | F1-score: 0.5255215402805444\n",
      "Iter: 1000 | Train Loss: 0.28805026412010193 | Val Loss: 0.3299011434569504 | F1-score: 0.5491765863967664\n",
      "Iter: 1100 | Train Loss: 0.30091235041618347 | Val Loss: 0.3270245591799418 | F1-score: 0.5525764028231304\n",
      "Iter: 1200 | Train Loss: 0.33464232087135315 | Val Loss: 0.33175471966916864 | F1-score: 0.5553726255893708\n",
      "Iter: 1300 | Train Loss: 0.3384143114089966 | Val Loss: 0.33246833356944 | F1-score: 0.5518299865000176\n",
      "Iter: 1400 | Train Loss: 0.31142958998680115 | Val Loss: 0.32677542260198883 | F1-score: 0.527587708198663\n",
      "Iter: 1500 | Train Loss: 0.32303571701049805 | Val Loss: 0.32207991318269213 | F1-score: 0.4471763607227441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:25:59,286] Trial 10 finished with value: 0.5207667489244481 and parameters: {'n_layers': 7, 'n_p': 0.7323519637834079, 'lr': 0.0009822010520626038, 'weight_decay': 1.0107130333640998e-05, 'batch_size': 530, 'n_0_size': 368, 'n_1_size': 202, 'n_2_size': 561, 'n_3_size': 794, 'n_4_size': 482, 'n_5_size': 331, 'n_6_size': 423}. Best is trial 4 with value: 0.5347317857573731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.2893630266189575 | Val Loss: 0.3318834196437489 | F1-score: 0.33463144844228576\n",
      "Iter: 200 | Train Loss: 0.32275494933128357 | Val Loss: 0.3274495285568815 | F1-score: 0.5401156698212479\n",
      "Iter: 300 | Train Loss: 0.31240934133529663 | Val Loss: 0.3196313959179503 | F1-score: 0.5036724092382374\n",
      "Iter: 400 | Train Loss: 0.2651783227920532 | Val Loss: 0.32887907371376507 | F1-score: 0.43610690398649743\n",
      "Iter: 500 | Train Loss: 0.3147849440574646 | Val Loss: 0.31886555660854676 | F1-score: 0.5126744391340197\n",
      "Iter: 600 | Train Loss: 0.32829129695892334 | Val Loss: 0.3181834527940461 | F1-score: 0.55546507600582\n",
      "Iter: 700 | Train Loss: 0.30847689509391785 | Val Loss: 0.3208862868222323 | F1-score: 0.5130933116782794\n",
      "Iter: 800 | Train Loss: 0.32464709877967834 | Val Loss: 0.32076359156406287 | F1-score: 0.5691053298386661\n",
      "Iter: 900 | Train Loss: 0.3434131443500519 | Val Loss: 0.31881829780159576 | F1-score: 0.5470492045084636\n",
      "Iter: 1000 | Train Loss: 0.30720585584640503 | Val Loss: 0.3403033596096616 | F1-score: 0.44329276771256415\n",
      "Iter: 1100 | Train Loss: 0.2722594141960144 | Val Loss: 0.3257940023234397 | F1-score: 0.5477550788359209\n",
      "Iter: 1200 | Train Loss: 0.3071446716785431 | Val Loss: 0.33627140341383055 | F1-score: 0.5396796329454941\n",
      "Iter: 1300 | Train Loss: 0.30405882000923157 | Val Loss: 0.33682889242966974 | F1-score: 0.48268720778551966\n",
      "Iter: 1400 | Train Loss: 0.26599380373954773 | Val Loss: 0.3404619029977105 | F1-score: 0.4885672809499683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:26:47,402] Trial 11 finished with value: 0.5383962398827677 and parameters: {'n_layers': 7, 'n_p': 0.40670915618380676, 'lr': 0.0009653082312080798, 'weight_decay': 6.59511714896153e-05, 'batch_size': 544, 'n_0_size': 737, 'n_1_size': 319, 'n_2_size': 585, 'n_3_size': 549, 'n_4_size': 702, 'n_5_size': 546, 'n_6_size': 739}. Best is trial 11 with value: 0.5383962398827677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1500 | Train Loss: 0.25583675503730774 | Val Loss: 0.3515882130825158 | F1-score: 0.5293688250310493\n",
      "Iter: 100 | Train Loss: 0.3844708800315857 | Val Loss: 0.32427364867180586 | F1-score: 0.411692351102829\n",
      "Iter: 200 | Train Loss: 0.3491833209991455 | Val Loss: 0.32116068340837955 | F1-score: 0.5218834057450294\n",
      "Iter: 300 | Train Loss: 0.32820573449134827 | Val Loss: 0.3199938340112567 | F1-score: 0.5320815891027451\n",
      "Iter: 400 | Train Loss: 0.2950335741043091 | Val Loss: 0.3213671799749136 | F1-score: 0.5593882761895657\n",
      "Iter: 500 | Train Loss: 0.28905758261680603 | Val Loss: 0.31732874643057585 | F1-score: 0.5057059396058321\n",
      "Iter: 600 | Train Loss: 0.28704747557640076 | Val Loss: 0.3173232451081276 | F1-score: 0.5459356280043721\n",
      "Iter: 700 | Train Loss: 0.28718987107276917 | Val Loss: 0.320583269931376 | F1-score: 0.5386479729786515\n",
      "Iter: 800 | Train Loss: 0.30966490507125854 | Val Loss: 0.3190654693171382 | F1-score: 0.49738137051463127\n",
      "Iter: 900 | Train Loss: 0.2950204610824585 | Val Loss: 0.3323218394070864 | F1-score: 0.5801981687545776\n",
      "Iter: 1000 | Train Loss: 0.2795151472091675 | Val Loss: 0.3251866241917014 | F1-score: 0.5530747715383768\n",
      "Iter: 1100 | Train Loss: 0.2805432975292206 | Val Loss: 0.326820719987154 | F1-score: 0.5447850367054343\n",
      "Iter: 1200 | Train Loss: 0.2522663474082947 | Val Loss: 0.34539111889898777 | F1-score: 0.5642436500638723\n",
      "Iter: 1300 | Train Loss: 0.29445546865463257 | Val Loss: 0.33638718351721764 | F1-score: 0.4616610910743475\n",
      "Iter: 1400 | Train Loss: 0.3197810649871826 | Val Loss: 0.3418375048786402 | F1-score: 0.5802370104938745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:27:30,913] Trial 12 finished with value: 0.5163409793749452 and parameters: {'n_layers': 7, 'n_p': 0.4042275332531814, 'lr': 0.0009754243680967522, 'weight_decay': 6.795246004931467e-05, 'batch_size': 550, 'n_0_size': 785, 'n_1_size': 357, 'n_2_size': 589, 'n_3_size': 627, 'n_4_size': 763, 'n_5_size': 538, 'n_6_size': 764}. Best is trial 11 with value: 0.5383962398827677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.34673944115638733 | Val Loss: 0.32599765547486237 | F1-score: 0.2974002004362816\n",
      "Iter: 200 | Train Loss: 0.31937190890312195 | Val Loss: 0.32339253675105956 | F1-score: 0.49971635743629095\n",
      "Iter: 300 | Train Loss: 0.28722015023231506 | Val Loss: 0.3238562712835713 | F1-score: 0.4783375921637514\n",
      "Iter: 400 | Train Loss: 0.3753952383995056 | Val Loss: 0.3206509926984477 | F1-score: 0.5393027399861535\n",
      "Iter: 500 | Train Loss: 0.29914867877960205 | Val Loss: 0.3200455370337465 | F1-score: 0.5501037302405335\n",
      "Iter: 600 | Train Loss: 0.2945184111595154 | Val Loss: 0.3187893033027648 | F1-score: 0.4971228131028109\n",
      "Iter: 700 | Train Loss: 0.31165677309036255 | Val Loss: 0.31871788515601046 | F1-score: 0.5495023872963217\n",
      "Iter: 800 | Train Loss: 0.31641271710395813 | Val Loss: 0.31766843310622284 | F1-score: 0.5446318880070088\n",
      "Iter: 900 | Train Loss: 0.3335558772087097 | Val Loss: 0.3221820495849433 | F1-score: 0.572797011497409\n",
      "Iter: 1000 | Train Loss: 0.29747599363327026 | Val Loss: 0.32219461715498626 | F1-score: 0.5427263247412304\n",
      "Iter: 1100 | Train Loss: 0.3116705119609833 | Val Loss: 0.31906201881031654 | F1-score: 0.5157147153865459\n",
      "Iter: 1200 | Train Loss: 0.3287127912044525 | Val Loss: 0.3270077691521755 | F1-score: 0.46943143218062644\n",
      "Iter: 1300 | Train Loss: 0.3153110146522522 | Val Loss: 0.32459581175515817 | F1-score: 0.5839335370895474\n",
      "Iter: 1400 | Train Loss: 0.2908341884613037 | Val Loss: 0.32300809199033786 | F1-score: 0.566736507554387\n",
      "Iter: 1500 | Train Loss: 0.2922564148902893 | Val Loss: 0.32633086415224294 | F1-score: 0.5271413478740425\n",
      "Iter: 1600 | Train Loss: 0.26180315017700195 | Val Loss: 0.3255682199500328 | F1-score: 0.5213144837423814\n",
      "Iter: 1700 | Train Loss: 0.26948362588882446 | Val Loss: 0.3229439958583477 | F1-score: 0.5533365045869073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:28:20,155] Trial 13 finished with value: 0.5304190294687138 and parameters: {'n_layers': 7, 'n_p': 0.5185082843765887, 'lr': 0.0008988013449612456, 'weight_decay': 6.429838367419304e-05, 'batch_size': 413, 'n_0_size': 402, 'n_1_size': 799, 'n_2_size': 381, 'n_3_size': 772, 'n_4_size': 589, 'n_5_size': 517, 'n_6_size': 643}. Best is trial 11 with value: 0.5383962398827677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1800 | Train Loss: 0.2567504346370697 | Val Loss: 0.32996877750685044 | F1-score: 0.5586120985275091\n",
      "Iter: 100 | Train Loss: 0.30375775694847107 | Val Loss: 0.3274324623977437 | F1-score: 0.48630378789761497\n",
      "Iter: 200 | Train Loss: 0.34546592831611633 | Val Loss: 0.3221020698547363 | F1-score: 0.37567037957556104\n",
      "Iter: 300 | Train Loss: 0.3447607457637787 | Val Loss: 0.3237462411908543 | F1-score: 0.5394167829962339\n",
      "Iter: 400 | Train Loss: 0.30546918511390686 | Val Loss: 0.31808746211669015 | F1-score: 0.508367345613592\n",
      "Iter: 500 | Train Loss: 0.30257630348205566 | Val Loss: 0.3173532643738915 | F1-score: 0.5391222992364098\n",
      "Iter: 600 | Train Loss: 0.2893749177455902 | Val Loss: 0.3173109994215123 | F1-score: 0.49309216352070084\n",
      "Iter: 700 | Train Loss: 0.35124489665031433 | Val Loss: 0.3185389120789134 | F1-score: 0.5491680301287595\n",
      "Iter: 800 | Train Loss: 0.31514984369277954 | Val Loss: 0.32247425002210284 | F1-score: 0.5435613034402623\n",
      "Iter: 900 | Train Loss: 0.2921733856201172 | Val Loss: 0.3213067019686979 | F1-score: 0.547415761386647\n",
      "Iter: 1000 | Train Loss: 0.3147948086261749 | Val Loss: 0.3205248345347011 | F1-score: 0.4949894117958406\n",
      "Iter: 1100 | Train Loss: 0.2809801399707794 | Val Loss: 0.3360401006305919 | F1-score: 0.43519366576391116\n",
      "Iter: 1200 | Train Loss: 0.2705049514770508 | Val Loss: 0.33216868691584645 | F1-score: 0.5130981706521089\n",
      "Iter: 1300 | Train Loss: 0.2751574218273163 | Val Loss: 0.3378884932574103 | F1-score: 0.5164953671834048\n",
      "Iter: 1400 | Train Loss: 0.2586098909378052 | Val Loss: 0.33749329517869386 | F1-score: 0.5007036985719906\n",
      "Iter: 1500 | Train Loss: 0.27874088287353516 | Val Loss: 0.3572147427236332 | F1-score: 0.4248300668071298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:28:49,596] Trial 14 finished with value: 0.5135272694569009 and parameters: {'n_layers': 6, 'n_p': 0.4094009709427492, 'lr': 0.0006885666435631375, 'weight_decay': 3.205632036030055e-05, 'batch_size': 517, 'n_0_size': 680, 'n_1_size': 217, 'n_2_size': 587, 'n_3_size': 573, 'n_4_size': 402, 'n_5_size': 611}. Best is trial 11 with value: 0.5383962398827677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.29940491914749146 | Val Loss: 0.326404282823205 | F1-score: 0.3772595366463065\n",
      "Iter: 200 | Train Loss: 0.3358238935470581 | Val Loss: 0.3279374521225691 | F1-score: 0.45249700732529163\n",
      "Iter: 300 | Train Loss: 0.3086170554161072 | Val Loss: 0.3176973797380924 | F1-score: 0.5468104332685471\n",
      "Iter: 400 | Train Loss: 0.32948482036590576 | Val Loss: 0.32764352578669786 | F1-score: 0.3994960505515337\n",
      "Iter: 500 | Train Loss: 0.295259565114975 | Val Loss: 0.31635855324566364 | F1-score: 0.5338243767619133\n",
      "Iter: 600 | Train Loss: 0.30069589614868164 | Val Loss: 0.31915686186403036 | F1-score: 0.5091995298862457\n",
      "Iter: 700 | Train Loss: 0.2986066937446594 | Val Loss: 0.31795551581308246 | F1-score: 0.37673268653452396\n",
      "Iter: 800 | Train Loss: 0.32080838084220886 | Val Loss: 0.30934899765998125 | F1-score: 0.5174997057765722\n",
      "Iter: 900 | Train Loss: 0.2985498309135437 | Val Loss: 0.3174650901928544 | F1-score: 0.5644718129187822\n",
      "Iter: 1000 | Train Loss: 0.29912397265434265 | Val Loss: 0.3250050889328122 | F1-score: 0.5124979168176651\n",
      "Iter: 1100 | Train Loss: 0.3525184988975525 | Val Loss: 0.32692883629351854 | F1-score: 0.5414135754108429\n",
      "Iter: 1200 | Train Loss: 0.3186412453651428 | Val Loss: 0.32403817400336266 | F1-score: 0.5299789980053902\n",
      "Iter: 1300 | Train Loss: 0.3266092538833618 | Val Loss: 0.3190038064494729 | F1-score: 0.5402106679975986\n",
      "Iter: 1400 | Train Loss: 0.30352696776390076 | Val Loss: 0.32982465624809265 | F1-score: 0.5684755966067314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:29:12,302] Trial 15 finished with value: 0.5385986318190893 and parameters: {'n_layers': 6, 'n_p': 0.4954359101550222, 'lr': 0.0009994663726591757, 'weight_decay': 5.628689161004867e-05, 'batch_size': 562, 'n_0_size': 288, 'n_1_size': 401, 'n_2_size': 202, 'n_3_size': 393, 'n_4_size': 603, 'n_5_size': 380}. Best is trial 15 with value: 0.5385986318190893.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.35113078355789185 | Val Loss: 0.3255263634266391 | F1-score: 0.33425183834568134\n",
      "Iter: 200 | Train Loss: 0.29335662722587585 | Val Loss: 0.32091712951660156 | F1-score: 0.4497422672087146\n",
      "Iter: 300 | Train Loss: 0.29528331756591797 | Val Loss: 0.32229738370064764 | F1-score: 0.5258149120115465\n",
      "Iter: 400 | Train Loss: 0.3280136287212372 | Val Loss: 0.3180208475359025 | F1-score: 0.45872538897299\n",
      "Iter: 500 | Train Loss: 0.3168405294418335 | Val Loss: 0.32488791211958856 | F1-score: 0.5677244096033035\n",
      "Iter: 600 | Train Loss: 0.3048000931739807 | Val Loss: 0.31792938132439885 | F1-score: 0.4885446410025319\n",
      "Iter: 700 | Train Loss: 0.35841864347457886 | Val Loss: 0.317327194636868 | F1-score: 0.5435549376472351\n",
      "Iter: 800 | Train Loss: 0.30768632888793945 | Val Loss: 0.3230556739914803 | F1-score: 0.5629175420730343\n",
      "Iter: 900 | Train Loss: 0.30766886472702026 | Val Loss: 0.32061427735513254 | F1-score: 0.5528096450913337\n",
      "Iter: 1000 | Train Loss: 0.28482288122177124 | Val Loss: 0.3203804521791397 | F1-score: 0.5292012470383798\n",
      "Iter: 1100 | Train Loss: 0.26489514112472534 | Val Loss: 0.3300392195101707 | F1-score: 0.5381647646427153\n",
      "Iter: 1200 | Train Loss: 0.3069411516189575 | Val Loss: 0.32642974488196835 | F1-score: 0.5313974147842777\n",
      "Iter: 1300 | Train Loss: 0.2790110111236572 | Val Loss: 0.3288645004072496 | F1-score: 0.562655859416531\n",
      "Iter: 1400 | Train Loss: 0.25177374482154846 | Val Loss: 0.33285092826812496 | F1-score: 0.4872581007019166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:29:37,974] Trial 16 finished with value: 0.4969416558742523 and parameters: {'n_layers': 6, 'n_p': 0.48510455551905557, 'lr': 0.0009786130179793425, 'weight_decay': 7.758355916114671e-05, 'batch_size': 565, 'n_0_size': 448, 'n_1_size': 422, 'n_2_size': 652, 'n_3_size': 401, 'n_4_size': 642, 'n_5_size': 308}. Best is trial 15 with value: 0.5385986318190893.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.3532312512397766 | Val Loss: 0.3261871318663319 | F1-score: 0.43940281291161815\n",
      "Iter: 200 | Train Loss: 0.29598817229270935 | Val Loss: 0.32092101343216434 | F1-score: 0.4945772895889897\n",
      "Iter: 300 | Train Loss: 0.287603497505188 | Val Loss: 0.3240248426314324 | F1-score: 0.5198654705478298\n",
      "Iter: 400 | Train Loss: 0.3231489658355713 | Val Loss: 0.31865115800211513 | F1-score: 0.4506959895933828\n",
      "Iter: 500 | Train Loss: 0.30427786707878113 | Val Loss: 0.31882293474289675 | F1-score: 0.5388843147985397\n",
      "Iter: 600 | Train Loss: 0.310683012008667 | Val Loss: 0.31724202921313627 | F1-score: 0.4880958968593228\n",
      "Iter: 700 | Train Loss: 0.3640676438808441 | Val Loss: 0.3160062980267309 | F1-score: 0.5230674013014762\n",
      "Iter: 800 | Train Loss: 0.30195921659469604 | Val Loss: 0.32030575506148806 | F1-score: 0.5342472080261474\n",
      "Iter: 900 | Train Loss: 0.2976703345775604 | Val Loss: 0.31990492151629546 | F1-score: 0.5609013765088973\n",
      "Iter: 1000 | Train Loss: 0.2822583019733429 | Val Loss: 0.32689504373458117 | F1-score: 0.5115516397260851\n",
      "Iter: 1100 | Train Loss: 0.2669979929924011 | Val Loss: 0.32639246121529614 | F1-score: 0.559572951447579\n",
      "Iter: 1200 | Train Loss: 0.307201087474823 | Val Loss: 0.32651787707882546 | F1-score: 0.5726051320952753\n",
      "Iter: 1300 | Train Loss: 0.28357407450675964 | Val Loss: 0.32633882953274634 | F1-score: 0.5496152264456595\n",
      "Iter: 1400 | Train Loss: 0.25128158926963806 | Val Loss: 0.33581317720874665 | F1-score: 0.4415782882321265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:30:02,587] Trial 17 finished with value: 0.4872864292513939 and parameters: {'n_layers': 6, 'n_p': 0.43712899780016135, 'lr': 0.0007061542662678891, 'weight_decay': 5.6388809033703694e-05, 'batch_size': 567, 'n_0_size': 321, 'n_1_size': 286, 'n_2_size': 518, 'n_3_size': 345, 'n_4_size': 785, 'n_5_size': 200}. Best is trial 15 with value: 0.5385986318190893.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.3483676016330719 | Val Loss: 0.32726851105689997 | F1-score: 0.3177953085137738\n",
      "Iter: 200 | Train Loss: 0.40340569615364075 | Val Loss: 0.32053145600689786 | F1-score: 0.5131091326475145\n",
      "Iter: 300 | Train Loss: 0.2971815764904022 | Val Loss: 0.3200489208102226 | F1-score: 0.4422950951589478\n",
      "Iter: 400 | Train Loss: 0.330337256193161 | Val Loss: 0.31858787602848476 | F1-score: 0.4426128185457654\n",
      "Iter: 500 | Train Loss: 0.26659727096557617 | Val Loss: 0.32494540595346016 | F1-score: 0.3482134569850233\n",
      "Iter: 600 | Train Loss: 0.36722928285598755 | Val Loss: 0.3176554292440415 | F1-score: 0.5489701959821912\n",
      "Iter: 700 | Train Loss: 0.3299413025379181 | Val Loss: 0.31863628658983434 | F1-score: 0.5400580565134684\n",
      "Iter: 800 | Train Loss: 0.28833600878715515 | Val Loss: 0.3413440129823156 | F1-score: 0.5237792366080815\n",
      "Iter: 900 | Train Loss: 0.3176054358482361 | Val Loss: 0.318166747689247 | F1-score: 0.5143757727411058\n",
      "Iter: 1000 | Train Loss: 0.31801411509513855 | Val Loss: 0.3217021036479209 | F1-score: 0.4901752687162823\n",
      "Iter: 1100 | Train Loss: 0.2711087763309479 | Val Loss: 0.32576353847980494 | F1-score: 0.5712953433394431\n",
      "Iter: 1200 | Train Loss: 0.28114545345306396 | Val Loss: 0.32429961197906065 | F1-score: 0.5618871682220037\n",
      "Iter: 1300 | Train Loss: 0.30181774497032166 | Val Loss: 0.32743393215868216 | F1-score: 0.5503537298904525\n",
      "Iter: 1400 | Train Loss: 0.3404892086982727 | Val Loss: 0.32574358665280867 | F1-score: 0.56304612590207\n",
      "Iter: 1500 | Train Loss: 0.2645432949066162 | Val Loss: 0.33424931681818426 | F1-score: 0.5431338498989741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:30:28,079] Trial 18 finished with value: 0.5019862624230208 and parameters: {'n_layers': 6, 'n_p': 0.4712305485090429, 'lr': 0.0009148524477490723, 'weight_decay': 5.680072279333931e-05, 'batch_size': 492, 'n_0_size': 706, 'n_1_size': 414, 'n_2_size': 385, 'n_3_size': 566, 'n_4_size': 578, 'n_5_size': 401}. Best is trial 15 with value: 0.5385986318190893.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1600 | Train Loss: 0.22975625097751617 | Val Loss: 0.33021521568298345 | F1-score: 0.522006252573596\n",
      "Iter: 100 | Train Loss: 0.3364828824996948 | Val Loss: 0.32877762856022014 | F1-score: 0.27785160560761735\n",
      "Iter: 200 | Train Loss: 0.2883179187774658 | Val Loss: 0.3216477815181978 | F1-score: 0.4254936720094374\n",
      "Iter: 300 | Train Loss: 0.28766512870788574 | Val Loss: 0.32113080736129523 | F1-score: 0.516929191927756\n",
      "Iter: 400 | Train Loss: 0.3064804971218109 | Val Loss: 0.3180778468808819 | F1-score: 0.5011974505839809\n",
      "Iter: 500 | Train Loss: 0.30540335178375244 | Val Loss: 0.32746578128107134 | F1-score: 0.55586471672981\n",
      "Iter: 600 | Train Loss: 0.29421693086624146 | Val Loss: 0.3177872328988968 | F1-score: 0.5185925297198757\n",
      "Iter: 700 | Train Loss: 0.35785403847694397 | Val Loss: 0.3172996688273646 | F1-score: 0.5449748577610137\n",
      "Iter: 800 | Train Loss: 0.30998319387435913 | Val Loss: 0.3207017673600105 | F1-score: 0.5308448403112349\n",
      "Iter: 900 | Train Loss: 0.28459441661834717 | Val Loss: 0.3242633063947001 | F1-score: 0.5507557815121066\n",
      "Iter: 1000 | Train Loss: 0.2866346836090088 | Val Loss: 0.32433605578637886 | F1-score: 0.5261861826142956\n",
      "Iter: 1100 | Train Loss: 0.2615627348423004 | Val Loss: 0.32988714883404396 | F1-score: 0.5558753648111897\n",
      "Iter: 1200 | Train Loss: 0.2812080681324005 | Val Loss: 0.3273142460853823 | F1-score: 0.5376009441191151\n",
      "Iter: 1300 | Train Loss: 0.30095693469047546 | Val Loss: 0.3355853076904051 | F1-score: 0.5715335972847476\n",
      "Iter: 1400 | Train Loss: 0.2735176682472229 | Val Loss: 0.3464285894747703 | F1-score: 0.4875690533268836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:30:56,202] Trial 19 finished with value: 0.5215882793549568 and parameters: {'n_layers': 7, 'n_p': 0.40059655714605513, 'lr': 0.000863313988691958, 'weight_decay': 7.477139889122756e-05, 'batch_size': 570, 'n_0_size': 577, 'n_1_size': 262, 'n_2_size': 234, 'n_3_size': 447, 'n_4_size': 686, 'n_5_size': 668, 'n_6_size': 262}. Best is trial 15 with value: 0.5385986318190893.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.34840887784957886 | Val Loss: 0.32775777841315545 | F1-score: 0.5053217691533706\n",
      "Iter: 200 | Train Loss: 0.3255932927131653 | Val Loss: 0.32516601769363185 | F1-score: 0.3362052545827978\n",
      "Iter: 300 | Train Loss: 0.3275311589241028 | Val Loss: 0.32334093223599825 | F1-score: 0.5472879295839984\n",
      "Iter: 400 | Train Loss: 0.32606732845306396 | Val Loss: 0.3204589153037352 | F1-score: 0.5376412728253533\n",
      "Iter: 500 | Train Loss: 0.34170985221862793 | Val Loss: 0.3175303804523804 | F1-score: 0.49435300862087933\n",
      "Iter: 600 | Train Loss: 0.29848799109458923 | Val Loss: 0.3198565560228685 | F1-score: 0.5538248463588603\n",
      "Iter: 700 | Train Loss: 0.3079957962036133 | Val Loss: 0.3154650654862909 | F1-score: 0.4984509576769437\n",
      "Iter: 800 | Train Loss: 0.3408004641532898 | Val Loss: 0.31848078878486863 | F1-score: 0.5427973095108483\n",
      "Iter: 900 | Train Loss: 0.3106962740421295 | Val Loss: 0.32572856808409967 | F1-score: 0.5736225703183343\n",
      "Iter: 1000 | Train Loss: 0.31251105666160583 | Val Loss: 0.3205234794055714 | F1-score: 0.5297522877945618\n",
      "Iter: 1100 | Train Loss: 0.2757717967033386 | Val Loss: 0.32238555918721584 | F1-score: 0.5631308012148912\n",
      "Iter: 1200 | Train Loss: 0.2969421148300171 | Val Loss: 0.32281315239036795 | F1-score: 0.5287775344708388\n",
      "Iter: 1300 | Train Loss: 0.28494706749916077 | Val Loss: 0.3318888396024704 | F1-score: 0.516577233286465\n",
      "Iter: 1400 | Train Loss: 0.27281296253204346 | Val Loss: 0.3315385978888063 | F1-score: 0.49789295915295106\n",
      "Iter: 1500 | Train Loss: 0.2650679051876068 | Val Loss: 0.3401232072535683 | F1-score: 0.5588352390948464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:31:33,166] Trial 20 finished with value: 0.5118670919362237 and parameters: {'n_layers': 6, 'n_p': 0.44607284733157776, 'lr': 0.0006678544116320948, 'weight_decay': 5.378201247499214e-05, 'batch_size': 524, 'n_0_size': 732, 'n_1_size': 407, 'n_2_size': 504, 'n_3_size': 558, 'n_4_size': 544, 'n_5_size': 436}. Best is trial 15 with value: 0.5385986318190893.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.29685309529304504 | Val Loss: 0.3261263813033248 | F1-score: 0.4419108403451515\n",
      "Iter: 200 | Train Loss: 0.36719831824302673 | Val Loss: 0.32446747837644646 | F1-score: 0.3993357460607182\n",
      "Iter: 300 | Train Loss: 0.33977729082107544 | Val Loss: 0.323425062678077 | F1-score: 0.37100654614694195\n",
      "Iter: 400 | Train Loss: 0.27398693561553955 | Val Loss: 0.32727789336984814 | F1-score: 0.3864252373124614\n",
      "Iter: 500 | Train Loss: 0.34651631116867065 | Val Loss: 0.3211113837632265 | F1-score: 0.4343234445109511\n",
      "Iter: 600 | Train Loss: 0.32099995017051697 | Val Loss: 0.32040204965707036 | F1-score: 0.561877842202331\n",
      "Iter: 700 | Train Loss: 0.30512064695358276 | Val Loss: 0.31791700738849066 | F1-score: 0.506516956018679\n",
      "Iter: 800 | Train Loss: 0.3386886715888977 | Val Loss: 0.3156667125947548 | F1-score: 0.5380363039898148\n",
      "Iter: 900 | Train Loss: 0.341646283864975 | Val Loss: 0.31524058002414124 | F1-score: 0.5662391872117013\n",
      "Iter: 1000 | Train Loss: 0.28492334485054016 | Val Loss: 0.32005322431073036 | F1-score: 0.5336770036003806\n",
      "Iter: 1100 | Train Loss: 0.2854138910770416 | Val Loss: 0.31955576304233435 | F1-score: 0.5537163795846881\n",
      "Iter: 1200 | Train Loss: 0.304118275642395 | Val Loss: 0.31728869225039635 | F1-score: 0.558195274887663\n",
      "Iter: 1300 | Train Loss: 0.3221522569656372 | Val Loss: 0.3183084455403413 | F1-score: 0.47615830284176447\n",
      "Iter: 1400 | Train Loss: 0.2736990749835968 | Val Loss: 0.31759804622693494 | F1-score: 0.5206873407869628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:32:00,021] Trial 21 finished with value: 0.5541569220297263 and parameters: {'n_layers': 7, 'n_p': 0.5527523424130752, 'lr': 0.000990715723353531, 'weight_decay': 4.680827704901506e-05, 'batch_size': 543, 'n_0_size': 276, 'n_1_size': 365, 'n_2_size': 284, 'n_3_size': 729, 'n_4_size': 418, 'n_5_size': 470, 'n_6_size': 483}. Best is trial 21 with value: 0.5541569220297263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1500 | Train Loss: 0.30434882640838623 | Val Loss: 0.3196881016095479 | F1-score: 0.5368295248710747\n",
      "Iter: 100 | Train Loss: 0.3380526304244995 | Val Loss: 0.3284001883232232 | F1-score: 0.4384218761415193\n",
      "Iter: 200 | Train Loss: 0.3659990131855011 | Val Loss: 0.3223878172310916 | F1-score: 0.3840836349761847\n",
      "Iter: 300 | Train Loss: 0.3056815564632416 | Val Loss: 0.3210319768298757 | F1-score: 0.45552724238597986\n",
      "Iter: 400 | Train Loss: 0.3290694057941437 | Val Loss: 0.3203299388741002 | F1-score: 0.4449732077844215\n",
      "Iter: 500 | Train Loss: 0.28578850626945496 | Val Loss: 0.31902861685463874 | F1-score: 0.4947875602678819\n",
      "Iter: 600 | Train Loss: 0.30991071462631226 | Val Loss: 0.31800113392598706 | F1-score: 0.4569636556235226\n",
      "Iter: 700 | Train Loss: 0.3452291786670685 | Val Loss: 0.3167224932800641 | F1-score: 0.532166159514225\n",
      "Iter: 800 | Train Loss: 0.3557697832584381 | Val Loss: 0.31654421127203736 | F1-score: 0.5454061428705853\n",
      "Iter: 900 | Train Loss: 0.34891560673713684 | Val Loss: 0.3175832719513864 | F1-score: 0.47735583330645714\n",
      "Iter: 1000 | Train Loss: 0.32203811407089233 | Val Loss: 0.32270031354644074 | F1-score: 0.5550074387680399\n",
      "Iter: 1100 | Train Loss: 0.31484469771385193 | Val Loss: 0.3193281870899778 | F1-score: 0.5520216903903268\n",
      "Iter: 1200 | Train Loss: 0.37492817640304565 | Val Loss: 0.31566274437037367 | F1-score: 0.5579367144541306\n",
      "Iter: 1300 | Train Loss: 0.261977881193161 | Val Loss: 0.31802066618745983 | F1-score: 0.5518717494877902\n",
      "Iter: 1400 | Train Loss: 0.35333797335624695 | Val Loss: 0.32101726441672357 | F1-score: 0.5124442306431858\n",
      "Iter: 1500 | Train Loss: 0.28012892603874207 | Val Loss: 0.3199008170402411 | F1-score: 0.512202855312463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 04:32:29,212] Trial 22 finished with value: 0.545169672279647 and parameters: {'n_layers': 7, 'n_p': 0.5671581365312748, 'lr': 0.0009745327633390806, 'weight_decay': 5.960318813946822e-05, 'batch_size': 538, 'n_0_size': 304, 'n_1_size': 450, 'n_2_size': 255, 'n_3_size': 721, 'n_4_size': 381, 'n_5_size': 406, 'n_6_size': 560}. Best is trial 21 with value: 0.5541569220297263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100 | Train Loss: 0.2883281409740448 | Val Loss: 0.32722328266789835 | F1-score: 0.25546921164758746\n",
      "Iter: 200 | Train Loss: 0.3119112253189087 | Val Loss: 0.3209892434458579 | F1-score: 0.43695792459672494\n",
      "Iter: 300 | Train Loss: 0.33613675832748413 | Val Loss: 0.322852183734217 | F1-score: 0.4390075677825558\n",
      "Iter: 400 | Train Loss: 0.3319854438304901 | Val Loss: 0.31766541061862824 | F1-score: 0.5040416198392068\n",
      "Iter: 500 | Train Loss: 0.32106688618659973 | Val Loss: 0.31940829080920063 | F1-score: 0.47608529656164117\n",
      "Iter: 600 | Train Loss: 0.3242288827896118 | Val Loss: 0.3207703790357036 | F1-score: 0.5310812313710489\n",
      "Iter: 700 | Train Loss: 0.32209861278533936 | Val Loss: 0.3174079473941557 | F1-score: 0.5363087394545154\n",
      "Iter: 800 | Train Loss: 0.2854755222797394 | Val Loss: 0.3176196082945793 | F1-score: 0.5086246017486818\n",
      "Iter: 900 | Train Loss: 0.3160615861415863 | Val Loss: 0.3183236468222834 | F1-score: 0.4873476595647874\n",
      "Iter: 1000 | Train Loss: 0.30069252848625183 | Val Loss: 0.31971020371683184 | F1-score: 0.478448663988421\n",
      "Iter: 1100 | Train Loss: 0.31400996446609497 | Val Loss: 0.3306797166024485 | F1-score: 0.47025199474826945\n",
      "Iter: 1200 | Train Loss: 0.31904473900794983 | Val Loss: 0.3203729227665932 | F1-score: 0.5615455248663502\n",
      "Iter: 1300 | Train Loss: 0.2856075167655945 | Val Loss: 0.32340147322224033 | F1-score: 0.496578969301716\n",
      "Iter: 1400 | Train Loss: 0.2809585630893707 | Val Loss: 0.32072993247739734 | F1-score: 0.5532323650775416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-12-04 04:32:58,421] Trial 23 failed with parameters: {'n_layers': 7, 'n_p': 0.5552792636373135, 'lr': 0.0009938124997151596, 'weight_decay': 3.563732372793427e-05, 'batch_size': 575, 'n_0_size': 309, 'n_1_size': 531, 'n_2_size': 252, 'n_3_size': 734, 'n_4_size': 379, 'n_5_size': 376, 'n_6_size': 556} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\astus\\code\\extractive-summarization\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\astus\\AppData\\Local\\Temp\\ipykernel_10164\\356372157.py\", line 89, in train_MLP\n",
      "    json.dump(results, open(f\"models/mlp_results_{trial.number}.json\", \"w\"))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\astus\\code\\extractive-summarization\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 310, in _modified_open\n",
      "    return io_open(file, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen codecs>\", line 186, in __init__\n",
      "KeyboardInterrupt\n",
      "[W 2023-12-04 04:32:58,432] Trial 23 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\astus\\code\\extractive-summarization\\gcn.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/astus/code/extractive-summarization/gcn.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/astus/code/extractive-summarization/gcn.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(train_MLP, n_trials\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\astus\\code\\extractive-summarization\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\astus\\code\\extractive-summarization\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\astus\\code\\extractive-summarization\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\astus\\code\\extractive-summarization\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\astus\\code\\extractive-summarization\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32mc:\\Users\\astus\\code\\extractive-summarization\\gcn.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/astus/code/extractive-summarization/gcn.ipynb#W6sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m torch\u001b[39m.\u001b[39msave(best_weights, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels/mlp_\u001b[39m\u001b[39m{\u001b[39;00mtrial\u001b[39m.\u001b[39mnumber\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/astus/code/extractive-summarization/gcn.ipynb#W6sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m results \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/astus/code/extractive-summarization/gcn.ipynb#W6sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m : final_score,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/astus/code/extractive-summarization/gcn.ipynb#W6sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m : params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/astus/code/extractive-summarization/gcn.ipynb#W6sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mf1_score\u001b[39m\u001b[39m\"\u001b[39m : hst_f1_score, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/astus/code/extractive-summarization/gcn.ipynb#W6sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/astus/code/extractive-summarization/gcn.ipynb#W6sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m json\u001b[39m.\u001b[39mdump(results, \u001b[39mopen\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodels/mlp_results_\u001b[39;49m\u001b[39m{\u001b[39;49;00mtrial\u001b[39m.\u001b[39;49mnumber\u001b[39m}\u001b[39;49;00m\u001b[39m.json\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/astus/code/extractive-summarization/gcn.ipynb#W6sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39mreturn\u001b[39;00m final_score\n",
      "File \u001b[1;32mc:\\Users\\astus\\code\\extractive-summarization\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m<frozen codecs>:186\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, errors)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(train_MLP, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "score = {}\n",
    "for item in Path(\"models\").iterdir():\n",
    "    if not item.suffix == \".json\" : continue\n",
    "    \n",
    "    id = item.stem[-1]\n",
    "    score[id] = json.load(open(item, \"r\"))[\"score\"]\n",
    "\n",
    "sorted(score.items(), key=lambda x : x[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
