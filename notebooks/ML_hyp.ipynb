{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "import src.custom_utils as custom_utils\n",
    "\n",
    "torch.set_default_device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # importing data\n",
    "# with open('../data/combine_true/X_train.json', 'r') as json_file:\n",
    "#     X_train = json.load(json_file)\n",
    "   \n",
    "# with open('../data/combine_true/y_train.json', 'r') as json_file:\n",
    "#     y_train = json.load(json_file)\n",
    "   \n",
    "# with open('../data/combine_true/X_test.json', 'r') as json_file:\n",
    "#     X_test = json.load(json_file) \n",
    "\n",
    "# with open('../data/combine_true/y_test.json', 'r') as json_file:\n",
    "#     y_test = json.load(json_file)\n",
    "    \n",
    "# # converting to appropriate format (and device)\n",
    "# X_train = torch.Tensor(X_train).float()\n",
    "# y_train = torch.Tensor(y_train).long()\n",
    "\n",
    "# X_test = torch.Tensor(X_test).float()\n",
    "# y_test = torch.Tensor(y_test).long()\n",
    "\n",
    "# # getting shapes\n",
    "# num_features = X_train.shape[1]\n",
    "# num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "with open('../data/combine_false_full/X_train.json', 'r') as json_file:\n",
    "    X_train = json.load(json_file)\n",
    "   \n",
    "with open('../data/combine_false_full/y_train.json', 'r') as json_file:\n",
    "    y_train = json.load(json_file)\n",
    "   \n",
    "# with open('../data/combine_false/X_test.json', 'r') as json_file:\n",
    "#     X_test = json.load(json_file) \n",
    "\n",
    "# with open('../data/combine_false_full/y_test.json', 'r') as json_file:\n",
    "#     y_test = json.load(json_file)\n",
    "    \n",
    "# converting to appropriate format (and device)\n",
    "X_train = torch.Tensor(X_train).float()\n",
    "y_train = torch.Tensor(y_train).long()\n",
    "\n",
    "# X_test = torch.Tensor(X_test).float()\n",
    "# y_test = torch.Tensor(y_test).long()\n",
    "\n",
    "# getting shapes\n",
    "num_features = X_train.shape[1]\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_RF(trial):\n",
    "    n_folds = 5\n",
    "    avg_score = 0\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        # Selecting fold train and validation\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_valid_fold = X_train[val_idx]\n",
    "        y_valid_fold = y_train[val_idx]\n",
    "        \n",
    "        # Hyperparameters for Random Forest\n",
    "        n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
    "        max_depth = trial.suggest_int('max_depth', 5, 100)\n",
    "        min_samples_split = trial.suggest_float('min_samples_split', 0.1, 1.0)\n",
    "        min_samples_leaf = trial.suggest_float('min_samples_leaf', 0.1, 0.5)\n",
    "        \n",
    "        # Create and train Random Forest model\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42  # You can adjust this for reproducibility\n",
    "        )\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Evaluate performance\n",
    "        y_pred = model.predict(X_valid_fold)\n",
    "        score = f1_score(y_valid_fold, y_pred, average='binary')  # Assuming binary classification\n",
    "        \n",
    "        avg_score += score / n_folds\n",
    "    \n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-02 21:15:08,770] A new study created in memory with name: no-name-62da9d1b-0ab4-42b3-bb91-7ea9c34a2285\n",
      "[I 2023-12-02 21:15:39,111] Trial 0 finished with value: 0.0 and parameters: {'n_estimators': 58, 'max_depth': 18, 'min_samples_split': 0.22137575729059794, 'min_samples_leaf': 0.17831503384491945}. Best is trial 0 with value: 0.0.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_RF, n_trials=N_TRIALS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_XGB(trial):\n",
    "    n_folds = 5\n",
    "    avg_score = 0\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        # Selecting fold train and validation\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_valid_fold = X_train[val_idx]\n",
    "        y_valid_fold = y_train[val_idx]\n",
    "        \n",
    "        # Hyperparameters for XGBoost\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 10, 100),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 50),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
    "            'min_child_weight': trial.suggest_float('min_child_weight', 1, 10),\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss',\n",
    "            'random_state': 42  # You can adjust this for reproducibility\n",
    "        }\n",
    "        \n",
    "        # Create and train XGBoost model\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X_train_fold, y_train_fold, eval_set=[(X_valid_fold, y_valid_fold)], verbose=False, **{'early_stopping_rounds': 10})\n",
    "        \n",
    "        # Evaluate performance\n",
    "        y_pred = model.predict(X_valid_fold)\n",
    "        score = f1_score(y_valid_fold, y_pred, average='binary')  # Assuming binary classification\n",
    "        \n",
    "        avg_score += score / n_folds\n",
    "    \n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-02 21:15:39,259] A new study created in memory with name: no-name-e8031a49-0c9f-4707-a9d7-50eb03b40194\n",
      "[I 2023-12-02 21:18:28,765] Trial 0 finished with value: 0.11004403111898922 and parameters: {'n_estimators': 58, 'max_depth': 55, 'learning_rate': 0.01822354886884994, 'subsample': 0.49001009793614614, 'colsample_bytree': 0.7757923583948666, 'gamma': 0.14104952479183452, 'min_child_weight': 4.599690775752921}. Best is trial 0 with value: 0.11004403111898922.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_XGB, n_trials=N_TRIALS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def objective_LGBM(trial):\n",
    "    n_folds = 5\n",
    "    avg_score = 0\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        # Selecting fold train and validation\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_valid_fold = X_train[val_idx]\n",
    "        y_valid_fold = y_train[val_idx]\n",
    "        \n",
    "        # Hyperparameters for LightGBM\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.1, 1.0),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "            'random_state': 42,  # You can adjust this for reproducibility\n",
    "        }\n",
    "        \n",
    "        # Create and train LightGBM model\n",
    "        d_train = lgb.Dataset(X_train_fold, label=y_train_fold)\n",
    "        d_valid = lgb.Dataset(X_valid_fold, label=y_valid_fold, reference=d_train)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            d_train,\n",
    "            valid_sets=[d_valid],\n",
    "            num_boost_round=1000,  # You can adjust the number of boosting rounds\n",
    "            early_stopping_rounds=10,  # Early stopping rounds\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        # Evaluate performance\n",
    "        y_pred = model.predict(X_valid_fold, num_iteration=model.best_iteration)\n",
    "        y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "        \n",
    "        score = f1_score(y_valid_fold, y_pred_binary, average='binary')  # Assuming binary classification\n",
    "        \n",
    "        avg_score += score / n_folds\n",
    "    \n",
    "    return avg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-02 20:29:35,008] A new study created in memory with name: no-name-239fe368-7d07-47e4-a9b7-eda9c6183171\n",
      "[W 2023-12-02 20:29:35,077] Trial 0 failed with parameters: {'num_leaves': 64, 'learning_rate': 0.0027627360244080273, 'feature_fraction': 0.1257642049203703, 'bagging_fraction': 0.2868202336170464, 'bagging_freq': 1, 'min_child_samples': 7} because of the following error: TypeError(\"train() got an unexpected keyword argument 'early_stopping_rounds'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nicolas/Documents/projects/extractive-summarization/env/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_27121/1810493956.py\", line 35, in objective_LGBM\n",
      "    model = lgb.train(\n",
      "            ^^^^^^^^^^\n",
      "TypeError: train() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "[W 2023-12-02 20:29:35,079] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective_LGBM, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/projects/extractive-summarization/env/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/projects/extractive-summarization/env/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/projects/extractive-summarization/env/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Documents/projects/extractive-summarization/env/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Documents/projects/extractive-summarization/env/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[66], line 35\u001b[0m, in \u001b[0;36mobjective_LGBM\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     32\u001b[0m d_train \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(X_train_fold, label\u001b[39m=\u001b[39my_train_fold)\n\u001b[1;32m     33\u001b[0m d_valid \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(X_valid_fold, label\u001b[39m=\u001b[39my_valid_fold, reference\u001b[39m=\u001b[39md_train)\n\u001b[0;32m---> 35\u001b[0m model \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     36\u001b[0m     params,\n\u001b[1;32m     37\u001b[0m     d_train,\n\u001b[1;32m     38\u001b[0m     valid_sets\u001b[39m=\u001b[39;49m[d_valid],\n\u001b[1;32m     39\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,  \u001b[39m# You can adjust the number of boosting rounds\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,  \u001b[39m# Early stopping rounds\u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[39m# Evaluate performance\u001b[39;00m\n\u001b[1;32m     45\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_valid_fold, num_iteration\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mbest_iteration)\n",
      "\u001b[0;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_LGBM, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_LogisticRegression(trial):\n",
    "    n_folds = 5\n",
    "    avg_score = 0\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        # Selecting fold train and validation\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_valid_fold = X_train[val_idx]\n",
    "        y_valid_fold = y_train[val_idx]\n",
    "        \n",
    "        # Hyperparameters for Logistic Regression with Elastic Net\n",
    "        params = {\n",
    "            'C': trial.suggest_float('C', 0.001, 10.0),\n",
    "            'penalty': 'elasticnet',\n",
    "            'solver': 'saga',  # 'saga' is the appropriate solver for elastic net\n",
    "            'l1_ratio': trial.suggest_float('l1_ratio', 0.0, 1.0),\n",
    "            'max_iter': trial.suggest_int('max_iter', 50, 500),\n",
    "            'random_state': 42  # You can adjust this for reproducibility\n",
    "        }\n",
    "        \n",
    "        # Create and train Logistic Regression model with Elastic Net\n",
    "        model = LogisticRegression(**params)\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Evaluate performance\n",
    "        y_pred = model.predict(X_valid_fold)\n",
    "        score = f1_score(y_valid_fold, y_pred, average='binary')  # Assuming binary classification\n",
    "        \n",
    "        avg_score += score / n_folds\n",
    "    \n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-02 21:32:37,321] A new study created in memory with name: no-name-b36386ba-764d-4a91-95d7-7a5c49d0a29b\n",
      "[I 2023-12-02 21:33:25,508] Trial 0 finished with value: 0.4635860658566684 and parameters: {'C': 4.029977224386709, 'l1_ratio': 0.8558355080811554, 'max_iter': 94}. Best is trial 0 with value: 0.4635860658566684.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_LogisticRegression, n_trials=N_TRIALS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_GaussianNB(trial):\n",
    "    n_folds = 5\n",
    "    avg_score = 0\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        # Selecting fold train and validation\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_valid_fold = X_train[val_idx]\n",
    "        y_valid_fold = y_train[val_idx]\n",
    "        \n",
    "        # Create and train Gaussian Naive Bayes model\n",
    "        model = GaussianNB()\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Evaluate performance\n",
    "        y_pred = model.predict(X_valid_fold)\n",
    "        score = f1_score(y_valid_fold, y_pred, average='binary')  # Assuming binary classification\n",
    "        \n",
    "        avg_score += score / n_folds\n",
    "    \n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-02 21:32:21,190] A new study created in memory with name: no-name-47554e60-2b7b-45fa-b4c7-bde2f4bc777b\n",
      "[I 2023-12-02 21:32:22,524] Trial 0 finished with value: 0.5263261241469139 and parameters: {}. Best is trial 0 with value: 0.5263261241469139.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_GaussianNB, n_trials=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_SVM(trial):\n",
    "#     n_folds = 5\n",
    "#     avg_score = 0\n",
    "#     skf = StratifiedKFold(n_splits=n_folds)\n",
    "    \n",
    "#     for i, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "#         # Selecting fold train and validation\n",
    "#         X_train_fold = X_train[train_idx]\n",
    "#         y_train_fold = y_train[train_idx]\n",
    "#         X_valid_fold = X_train[val_idx]\n",
    "#         y_valid_fold = y_train[val_idx]\n",
    "        \n",
    "#         # Hyperparameters for SVM\n",
    "#         params = {\n",
    "#             'C': trial.suggest_float('C', 0.1, 10.0),\n",
    "#             'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly']),\n",
    "#             'gamma': trial.suggest_float('gamma', 0.1, 1.0, log=True),\n",
    "#             'random_state': 42  # You can adjust this for reproducibility\n",
    "#         }\n",
    "        \n",
    "#         # Create and train SVM model\n",
    "#         model = SVC(**params)\n",
    "#         model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "#         # Evaluate performance\n",
    "#         y_pred = model.predict(X_valid_fold)\n",
    "#         score = f1_score(y_valid_fold, y_pred, average='binary')  # Assuming binary classification\n",
    "        \n",
    "#         avg_score += score / n_folds\n",
    "    \n",
    "#     return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective_SVM, n_trials=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_KNN(trial):\n",
    "    n_folds = 5\n",
    "    avg_score = 0\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        # Selecting fold train and validation\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_valid_fold = X_train[val_idx]\n",
    "        y_valid_fold = y_train[val_idx]\n",
    "        \n",
    "        # Hyperparameters for KNN\n",
    "        params = {\n",
    "            'n_neighbors': trial.suggest_int('n_neighbors', 1, 20),\n",
    "            'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "            'p': trial.suggest_int('p', 1, 2),  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "        }\n",
    "        \n",
    "        # Create and train KNN model\n",
    "        model = KNeighborsClassifier(**params)\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Evaluate performance\n",
    "        y_pred = model.predict(X_valid_fold)\n",
    "        score = f1_score(y_valid_fold, y_pred, average='binary')  # Assuming binary classification\n",
    "        \n",
    "        avg_score += score / n_folds\n",
    "    \n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-02 21:19:33,258] A new study created in memory with name: no-name-0a510f3d-08e8-46b4-bedb-c8b1cd33fcff\n",
      "[I 2023-12-02 21:20:01,050] Trial 0 finished with value: 0.4429024662302684 and parameters: {'n_neighbors': 17, 'weights': 'uniform', 'p': 2}. Best is trial 0 with value: 0.4429024662302684.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_KNN, n_trials=N_TRIALS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
